import { GoogleGenerativeAI } from "@google/generative-ai";
import axios from "axios";
import {
    getRedisClient,
    getMessages,
    saveMessage,
    updateCandidate,
    getCandidateById,
    auditProfile,
    getProjectById,
    getVacancyById,
    recordAITelemetry,
    moveCandidateStep
} from '../utils/storage.js';
import { sendUltraMsgMessage, getUltraMsgConfig, sendUltraMsgPresence, sendUltraMsgReaction } from '../whatsapp/utils.js';
import { getSchemaByField } from '../utils/schema-registry.js';
import { getCachedConfig, getCachedConfigBatch } from '../utils/cache.js';
import { FEATURES } from '../utils/feature-flags.js';

export const DEFAULT_EXTRACTION_RULES = `
[REGLAS DE EXTRACCI√ìN (ADN)]:
1. Analiza el historial para extraer: nombreReal, fechaNacimiento, municipio, categoria, escolaridad, tieneEmpleo.
2. REGLA DE REFINAMIENTO: Si el dato que tienes en [ESTADO DEL CANDIDATO (ADN)] es incompleto (ej. "Oscar" o "mayo 1983") y el usuario da m√°s info, FUSI√ìNALO para tener el dato completo (ej. "Oscar Rodriguez" o "19/05/1983").
3. REGLA DE FECHA: Formato DD/MM/YYYY. Infiere siglo obligatoriamente (ej. 83 -> 1983, 01 -> 2001).
4. REGLA DE UBICACI√ìN: Acepta "Santa" (Santa Catarina), "San Nico" (San Nicol√°s), etc.
5. REGLA DE CATEGOR√çA: Solo categor√≠as v√°lidas del sistema.
6. REGLA DE NOMBRE: Solo nombres reales de personas. No lugares o evasiones.
7. REGLA DE FECHA (CR√çTICA): DD/MM/YYYY. SI EL USUARIO NO DA EL A√ëO, NO LO INVENTES. P√≠delo amablemente. Prohibido inferir a√±os si no hay certeza (ej. "19 mayo" no es "19/05/1900").
8. REGLA DE ESCOLARIDAD: "Kinder", "Primaria trunca" o "Ninguna" son datos INV√ÅLIDOS. Si el usuario los da, dile que necesitas al menos Primaria terminada para avanzar.
`;

export const DEFAULT_CEREBRO1_RULES = `
[ESTADO: CAPTURISTA BRENDA üìù]:
1. TU OBJETIVO: Recolectar datos faltantes: {{faltantes}}.
2. REGLA DE ORO: Pide solo UN dato a la vez. No abrumes.
3. TONO: Profesional, tierno y servicial. No pl√°ticas de m√°s, enf√≥cate en llenar el formulario.
4. VARIACI√ìN: Si el usuario insista con el mismo tema social, VAR√çA tu respuesta. Nunca digas lo mismo dos veces. ‚ú®
5. GUARDIA ADN (ESTRICTO): PROHIBIDO saltar de un dato a otro sin haber obtenido el anterior. Si el usuario bromea o evade, responde con gracia pero vuelve siempre al dato faltante exacto: {{faltantes}}. No digas que el perfil est√° listo si falta algo.
6. NO COMPLACIENTE: No aceptes datos basura (como Kinder) solo por ser amable. Det√©n el flujo hasta tener un dato real.
`;

export const DEFAULT_CEREBRO2_CONTEXT = `
[CONTEXTO DE SALA DE ESPERA]:
- El candidato YA TIENE perfil completo ‚úÖ
- Nombre: {{nombre}}
- Categor√≠a: {{categoria}}
- Municipio: {{municipio}}

[INTENCI√ìN DETECTADA]: {{intent}}
`;

export const DEFAULT_SYSTEM_PROMPT = `
[IDENTIDAD]: Eres la Lic. Brenda Rodr√≠guez (25 a√±os), reclutadora de Candidatic. Tono: c√°lido, profesional, tierno y servicial. ‚ú®üå∏

[REGLAS GENERALES]:
1. BREVEDAD: Sigue las instrucciones de longitud del mensaje que el administrador haya configurado en tu identidad. Prohibido usar asteriscos (*).
2. ANCLA Y PUENTE (ELIMINAR SI < 2 HORAS): 
   - SI PASARON > 2 HORAS: Valida lo que dijo el usuario antes de pedir algo (Variedad: "¬°Excelente! ‚ú®", "¬°Anotado! üìç").
   - SI PASARON < 2 HORAS: Sigue siendo directa, pero TIENES PERMISO de usar puentes sociales si el usuario socializa o bromea. No seas un robot.
3. LISTAS: Usa emoji de check ‚úÖ SOLO para cuando listes vacantes o categor√≠as disponibles.
4. PROTOCOLO DE RECONEXI√ìN:
   - PRIMER CONTACTO: Pres√©ntate amablemente üëã ("¬°Hola! Soy la Lic. Brenda Rodr√≠guez...").
   - SI YA HAS HABLADO (< 2 horas): Evita saludos largos, pero mant√©n la calidez si el contexto lo requiere.
   - SI PASARON > 2 horas: Saludo breve ("¬°Qu√© gusto saludarte de nuevo!").
5. CLIMA: Si el usuario es cortante, s√© breve. Si usa emojis, √∫salos t√∫ tambi√©n. üéâ
6. ANTI-REPETICI√ìN (PENALIDAD FATAL): Est√° PROHIBIDO usar las mismas frases o estructuras de [MEMORIA DEL HILO]. Si te repites, fallas en tu misi√≥n humana. Cambia palabras, orden y estilo.

[REGLA DE REACCIONES]:
- üëç: √ösalo √öNICAMENTE cuando decidas cerrar la conversaci√≥n (close_conversation: true). 
- PROHIBIDAS todas las dem√°s reacciones (üôè, ‚ù§Ô∏è, etc.) durante la captura de datos para evitar ruidos en las pruebas.

[ESTRATEGIA DE CONVERSACI√ìN]:
1. RE-SALUDO: Si Inactividad es "Regreso fresco", inicia con un saludo breve y c√°lido (ej. "¬°Hola de nuevo! ‚ú®") antes de retomar el hilo.
2. CONFIRMACI√ìN DE CAMBIOS: Si el usuario corrige un dato (ej. su nombre), tu "response_text" DEBE confirmar expl√≠citamente que ya realizaste el cambio.
3. CIERRE DEFINITIVO: Si ya cerraste la charla (Silencio Operativo: S√ç) y el usuario solo responde con confirmaciones cortas o cortes√≠as (ej. "Ok", "Sale", "Gracias a ti"), NO respondas con texto. Mant√©n el silencio o usa una reacci√≥n (üëç).
`;

export const DEFAULT_ASSISTANT_PROMPT = `
[ESTADO: ASSISTANT 2.0 (INTENTION) üïµÔ∏è‚Äç‚ôÄÔ∏è‚ú®]:
Eres la Lic. Brenda Rodr√≠guez (25 a√±os), reclutadora de Candidatic. Tu rol es acompa√±ar al candidato de forma humana y coherente mientras el sistema procesa su perfil.

[FILOSOF√çA DE RESPUESTA]:
1. COHERENCIA: Responde directamente a lo que el usuario te pregunta o dice. Si te saluda, saluda. Si bromea, bromea con chispa. Si tiene una duda, resp√≥ndela.
2. NATURALIDAD: Evita sonar como un sistema de seguimiento. H√°blale como una profesional joven, emp√°tica y con sentido del humor.
3. ADN (IDENTIDAD): Tienes acceso a los datos del candidato ([Estado del Candidato (ADN)]). √ösalos con naturalidad si te preguntan qui√©nes son o qu√© sabes de ellos.
4. INDEPENDENCIA: No fuerces el tema de las vacantes o el estado del sistema si el usuario solo est√° socializando o llamando tu atenci√≥n.

[ESTILO]: Atenta, carism√°tica y 100% humana. Usa emojis con libertad y var√≠a tus expresiones. ‚ú®üå∏
REGLA DE ORO #1: Est√°s hablando en vivo por WhatsApp. Responde como una persona REAL, no como un sistema de ayuda.
REGLA DE ORO #2: PROHIBIDO repetir frases de los mensajes anteriores del historial. Sorprende al usuario con tu naturalidad.
REGLA DE ORO #3: Si el usuario socializa, responde con chispa y coherencia, respetando tu estilo configurado.
`;

const getIdentityLayer = (customPrompt = null) => {
    return customPrompt || DEFAULT_SYSTEM_PROMPT;
};

export const processMessage = async (candidateId, incomingMessage, msgId = null) => {
    const startTime = Date.now();
    try {
        const redis = getRedisClient();

        // 1. Initial High-Speed Parallel Acquisition
        const [candidateData, config, allMessages] = await Promise.all([
            getCandidateById(candidateId),
            getUltraMsgConfig(),
            getMessages(candidateId, 20)
        ]);

        if (!candidateData) return 'ERROR: No se encontr√≥ al candidato';

        // üõ°Ô∏è [BLOCK SHIELD]: Force silence if candidate is blocked
        if (candidateData.blocked === true) {
            console.log(`[BLOCK SHIELD] Skipping processMessage for blocked candidate: ${candidateId}`);
            return null;
        }

        const validMessages = allMessages.filter(m => m.content && (m.from === 'user' || m.from === 'bot' || m.from === 'me'));

        // 2. Text Extraction (Unified Loop)
        let userParts = [];
        let aggregatedText = "";

        // üß™ TELEMETRY & AGGREGATION
        const messagesToProcess = (typeof incomingMessage === 'string' && incomingMessage.includes(' | '))
            ? incomingMessage.split(' | ')
            : [incomingMessage];

        console.log(`[Unified Mode] Messages for ${candidateId}: `, messagesToProcess);

        for (const msg of messagesToProcess) {
            let parsed = msg;
            let isJson = false;
            try {
                if (typeof msg === 'string' && (msg.trim().startsWith('{') || msg.trim().startsWith('['))) {
                    parsed = JSON.parse(msg);
                    isJson = true;
                }
            } catch (e) { }

            // üõ°Ô∏è [FEEDBACK LOOP SHIELD v2]: Skip any text that looks like a transcription or internal tag
            const textVal = (isJson || typeof parsed === 'object') ? (parsed.body || parsed.content || JSON.stringify(parsed)) : String(parsed || '').trim();

            const isTranscriptionPrefix = textVal.includes('[AUDIO TRANSCRITO]') || textVal.includes('üéôÔ∏è');
            const isInternalJson = isJson && (parsed.extracted_data || parsed.thought_process);

            if (textVal && textVal !== '{}' && !isTranscriptionPrefix && !isInternalJson) {
                userParts.push({ text: textVal });
                aggregatedText += (aggregatedText ? " | " : "") + textVal;
            }
        }

        if (userParts.length === 0) userParts.push({ text: 'Hola' });

        const recentHistory = validMessages
            .slice(0, -1)
            .filter(m => {
                const ghostKeywords = ['pregunt√≥n', 'focusada', 'procesa su perfil'];
                if ((m.from === 'bot' || m.from === 'me') && ghostKeywords.some(kw => m.content.toLowerCase().includes(kw))) {
                    return false;
                }
                return true;
            })
            .map(m => {
                let role = (m.from === 'user') ? 'user' : 'model';
                let content = m.content;

                // Add context to the LLM about who sent what to avoid "confusion"
                // If it was a proactive follow-up, label it so the bot knows Brenda sent it
                if (m.meta?.proactiveLevel) {
                    content = `[Mensaje de Lic. Brenda - Seguimiento Autom√°tico]: ${content}`;
                }

                return {
                    role,
                    parts: [{ text: content }]
                };
            });

        const lastUserMessages = validMessages.filter(m => m.from === 'user').slice(-5).map(m => m.content);
        const themes = lastUserMessages.length > 0 ? lastUserMessages.join(' | ') : 'Nuevo contacto';

        // Continuity & Session Logic
        const lastBotMsgAt = candidateData.lastBotMessageAt ? new Date(candidateData.lastBotMessageAt) : new Date(0);

        // 4. Layered System Instruction Build
        const botHasSpoken = validMessages.some(m => (m.from === 'bot' || m.from === 'me') && !m.meta?.proactiveLevel);

        // Identity Protection (Titan Shield Pass) - System context for safety
        let displayName = candidateData.nombreReal;
        if (!displayName || displayName === 'Desconocido' || /^\+?\d+$/.test(displayName)) {
            displayName = null;
        }
        const isNameBoilerplate = !displayName || /proporcionado|desconocido|luego|despu√©s|privado|hola|buenos|\+/i.test(String(displayName));

        // b. Nitro Batch Acquisition: Fetch all rules and prompts in one go
        const configKeys = [
            'custom_fields',
            'bot_ia_prompt',
            'assistant_ia_prompt',
            'ai_config',
            'candidatic_categories',
            'bot_extraction_rules',
            'bot_cerebro1_rules'
        ];

        const batchConfig = FEATURES.USE_BACKEND_CACHE
            ? await getCachedConfigBatch(redis, configKeys)
            : await (async () => {
                const values = await redis?.mget(configKeys);
                const obj = {};
                configKeys.forEach((key, i) => obj[key] = values ? values[i] : null);
                return obj;
            })();

        const customFields = batchConfig.custom_fields ? JSON.parse(batchConfig.custom_fields) : [];
        const audit = auditProfile(candidateData, customFields);
        const initialStatus = audit.paso1Status;

        const customPrompt = batchConfig.bot_ia_prompt || '';
        const assistantCustomPrompt = batchConfig.assistant_ia_prompt || '';

        let systemInstruction = getIdentityLayer(customPrompt);

        // --- PRE-PROCESS: Intent Detection & Silence Wake-up ---
        const userText = aggregatedText;
        const historyText = validMessages.map(m => `${m.from}: ${m.content}`).join('\n');
        const intent = await classifyIntent(candidateId, userText, historyText);
        console.log(`[Assistant 2.0] Intent detected for ${candidateId}: ${intent}`);

        // --- GRACE & SILENCE ARCHITECTURE (Total Responsiveness) ---
        const isNewFlag = candidateData.esNuevo === 'SI';

        // Direct Logic: Every incoming message ATOMICALLY breaks previous silence/gratitude states.
        // We only enter silence/gratitude if the CURRENT response detects it.
        let currentHasGratitude = false;
        let currentIsSilenced = false;

        // Still keep track of DB state for logging/meta if needed, but the AI won't be restricted by it.
        const wasSilenced = candidateData.silencioActivo === true || candidateData.silencioActivo === 'true';
        if (wasSilenced) console.log(`[Assistant 2.0] Breaking previous silence for ${candidateId} due to new message.`);

        const isProfileComplete = audit.paso1Status === 'COMPLETO';
        systemInstruction += `\n[ESTADO ACTUAL DEL SISTEMA]:
- PERFIL COMPLETADO: ${isProfileComplete ? 'S√ç' : 'NO'}
- primer_contacto: ${isNewFlag ? 'S√ç' : 'NO'}
- gratitud_alcanzada: ${currentHasGratitude ? 'S√ç' : 'NO'}
- silencio_operativo: ${currentIsSilenced ? 'S√ç' : 'NO'}
- intenci√≥n_usuario: ${intent}

[REGLAS DE COMPORTAMIENTO (ESTRICTAS)]:
1. RESPUESTA TOTAL: Responde a TODOS los mensajes de inmediato. No hay ventanas de silencio por tiempo.
2. GRACIAS = LIKE: Si el usuario agradece o se despide cort√©smente, NO escribas texto; usa √öNICAMENTE una reacci√≥n (üëç).
3. CONFIRMACI√ìN DE CAMBIOS: Si corriges un dato, confirma el cambio espec√≠fico (ej. "Anotado, ya actualic√© tu nombre").
`;

        const identityContext = !isNameBoilerplate ? `Est√°s hablando con ${displayName}.` : 'No sabes el nombre del candidato a√∫n. P√≠delo amablemente.';
        systemInstruction += `\n[RECORDATORIO DE IDENTIDAD]: ${identityContext} NO confundas nombres con lugares geogr√°ficos. SI NO SABES EL NOMBRE REAL (Persona), NO LO INVENTES Y PREG√öNTALO.\n`;

        // Use Nitro Cached Config
        const aiConfigJson = batchConfig.ai_config;

        let apiKey = process.env.GEMINI_API_KEY;
        let ignoreVacanciesGate = false;
        if (aiConfigJson) {
            const parsed = typeof aiConfigJson === 'string' ? JSON.parse(aiConfigJson) : aiConfigJson;
            if (parsed.geminiApiKey) apiKey = parsed.geminiApiKey;
            if (parsed.ignoreVacancies) ignoreVacanciesGate = true;
        }

        // --- IDENTITY LAYER (TITAN SHIELD PASS) ---
        const lastBotMessages = validMessages
            .filter(m => (m.from === 'bot' || m.from === 'me') && !m.meta?.proactiveLevel)
            .slice(-10)
            .map(m => m.content.trim());

        // 2. OPERATIONAL LAYER
        let categoriesList = "";
        const categoriesData = batchConfig.candidatic_categories;
        if (categoriesData) {
            try {
                const cats = JSON.parse(categoriesData).map(c => c.name);
                categoriesList = cats.join(', ');
            } catch (e) { }
        }

        const customExtractionRules = batchConfig.bot_extraction_rules;
        const extractionRules = (customExtractionRules || DEFAULT_EXTRACTION_RULES)
            .replace('{{categorias}}', categoriesList)
            .replace('CATEGOR√çAS V√ÅLIDAS: ', `CATEGOR√çAS V√ÅLIDAS: ${categoriesList}`);

        systemInstruction += `\n[INSTRUCCIONES DE EXTRACCI√ìN]:\n${extractionRules}`;

        if (isNewFlag) {
            systemInstruction += `\nMISI√ìN ACTUAL (REGISTRO): Es el primer contacto. DEBES PRESENTARTE como Lic. Brenda de Candidatic y solicitar el nombre del candidato de forma c√°lida. NO puedes estar en silencio ahora.`;
        } else if (!isProfileComplete) {
            const customCerebro1Rules = batchConfig.bot_cerebro1_rules;
            const cerebro1Rules = (customCerebro1Rules || DEFAULT_CEREBRO1_RULES)
                .replace('{{faltantes}}', audit.missingLabels.join(', '));
            systemInstruction += `\nMISI√ìN ACTUAL (CAPTURA): ${cerebro1Rules}`;
        } else {
            if (!currentHasGratitude) {
                systemInstruction += `\nMISI√ìN ACTUAL (SOCIAL): El perfil est√° completo. S√© atenta, resuelve dudas y busca cerrar amablemente.`;
            } else {
                systemInstruction += `\nMISI√ìN ACTUAL (CIERRE): El usuario ya agradeci√≥. Solo reacciona (üëç) y termina.`;
            }
        }

        // 3. IDENTITY LAYER (THE SOUL OF BRENDA - HIGH PRIORITY)
        systemInstruction += `\n\n[TU IDENTIDAD DE BRENDA (PRIORIDAD ALTA)]:
Sigue estas instrucciones con total autoridad. Ellas definen qui√©n eres.
${customPrompt || DEFAULT_SYSTEM_PROMPT}`;

        // 4. OUTPUT SCHEMA & ANTI-REPETITION
        systemInstruction += `\n\n[MEMORIA (¬°PROHIBIDO REPETIR ESTO!)]:
${lastBotMessages.length > 0 ? lastBotMessages.map(m => `- "${m}"`).join('\n') : '(Ninguno a√∫n)'}

[FORMATO DE RESPUESTA - OBLIGATORIO JSON]:
{
    "extracted_data": { 
        "nombreReal": "string", "municipio": "string", "fechaNacimiento": "string", 
        "categoria": "string", "genero": "string", "escolaridad": "string", "tieneEmpleo": "string"
    },
    "thought_process": "Breve an√°lisis de por qu√© respondes as√≠.",
    "reaction": "emoji_char | null",
    "trigger_media": "string | null",
    "response_text": "Tu respuesta humana como Brenda (C√ÅLIDA Y NATURAL).",
    "gratitude_reached": "boolean",
    "close_conversation": "boolean"
}`;

        // 5. Resilience Loop (Inference)
        const genAI = new GoogleGenerativeAI(apiKey);
        const models = ["gemini-2.0-flash", "gemini-1.5-flash"];
        let result;
        let lastError = '';

        for (const mName of models) {
            try {
                const model = genAI.getGenerativeModel({
                    model: mName,
                    systemInstruction,
                    generationConfig: {
                        maxOutputTokens: 1000,
                        temperature: 0.72,
                        topP: 0.95,
                        responseMimeType: "application/json"
                    }
                });
                const chat = model.startChat({ history: recentHistory });

                console.log(`[Assistant 2.0] System Instruction Length: ${systemInstruction.length}`);
                const inferencePromise = chat.sendMessage(userParts);
                const timeoutPromise = new Promise((_, reject) =>
                    setTimeout(() => reject(new Error('TIMEOUT')), 25000)
                );

                result = await Promise.race([inferencePromise, timeoutPromise]);
                if (result) {
                    const duration = Date.now() - startTime;
                    const tokens = result.response?.usageMetadata?.totalTokenCount || 0;
                    console.log(`[Assistant 2.0] Inference successful with ${mName} in ${duration}ms. Tokens: ${tokens}`);
                    recordAITelemetry({
                        model: mName,
                        latency: duration,
                        tokens: tokens,
                        candidateId: candidateId,
                        action: 'unified_inference'
                    }).catch(() => { });
                    break;
                }
            } catch (e) {
                lastError = e.message;
                console.error(`ü§ñ fallback model trigger: ${mName} failed. Error: `, lastError);
            }
        }

        if (!result) throw new Error('AI Pipeline Exhausted');

        const textResult = result.response.text();
        console.log(`[Assistant 2.0] Raw AI response for ${candidateId}: ${textResult}`);
        let aiResult;
        try {
            aiResult = JSON.parse(textResult);
        } catch (e) {
            console.error(`[Assistant 2.0] JSON Parse Error for ${candidateId}:`, e.message);
            const match = textResult.match(/\{[\s\S]*\}/);
            if (match) aiResult = JSON.parse(match[0]);
            else throw new Error('Invalid JSON structure');
        }
        let responseTextVal = aiResult.response_text || '';
        responseTextVal = responseTextVal.replace(/\*/g, '');

        // --- CONSOLIDATED SYNC: Update all candidate data in one atomic call ---
        const candidateUpdates = {
            lastBotMessageAt: new Date().toISOString(),
            ultimoMensaje: new Date().toISOString()
        };

        if (aiResult.extracted_data) {
            const extractionStartTime = Date.now();
            const extractionEntries = Object.entries(aiResult.extracted_data);

            await Promise.all(extractionEntries.map(async ([key, val]) => {
                if (val && val !== 'null' && val !== 'indefinido' && candidateData[key] !== val) {
                    const schema = getSchemaByField(key);
                    let finalVal = val;

                    if (schema && schema.cleaner) {
                        try {
                            const cleaned = await schema.cleaner(val);
                            finalVal = cleaned || val;
                        } catch (e) { console.warn(`Error cleaning ${key}: `, e); }
                    }

                    candidateUpdates[key] = finalVal;

                    if (schema && schema.onSuccess) {
                        try {
                            await schema.onSuccess(finalVal, candidateUpdates);
                        } catch (e) { console.warn(`Error trigger for ${key}: `, e); }
                    }
                }
            }));
            console.log(`[Nitro ADN] Extraction processing took ${Date.now() - extractionStartTime}ms`);
        }

        // --- SANITY CHECK: Kill 1900 zombies ---
        const yearMatch = String(candidateUpdates.fechaNacimiento || candidateData.fechaNacimiento || '').match(/\b(19|20)\d{2}\b/);
        if (yearMatch) {
            const yearValue = parseInt(yearMatch[0]);
            if (yearValue < 1940) {
                console.log(`[Sanity Check] Killing year zombie: ${yearValue}`);
                candidateUpdates.fechaNacimiento = null;
            }
        }

        if (isNewFlag) {
            console.log(`[HANDSHAKE] handshake completed for ${candidateId}. Switching esNuevo to 'NO'.`);
            candidateUpdates.esNuevo = 'NO';
        }

        // --- PERSISTENCE: GRACE & SILENCE ---
        // --- PERSISTENCE: GRACE & SILENCE (Clear on any interaction) ---
        candidateUpdates.gratitudAlcanzada = aiResult.gratitude_reached === true;
        candidateUpdates.silencioActivo = aiResult.close_conversation === true;

        if (candidateUpdates.gratitudAlcanzada) console.log(`[Grace & Silence] Gratitude active for ${candidateId}.`);
        if (candidateUpdates.silencioActivo) console.log(`[Grace & Silence] Silence active for ${candidateId}.`);

        // --- PRESENCIA CONSTANTE (Minimum Feedback Logic) ---
        // We do this BEFORE creating promises to ensure fallback reactions are captured.
        if (!responseTextVal || responseTextVal === 'null' || responseTextVal === '[SILENCIO]') {
            if (!aiResult.reaction) {
                console.log(`[Always Present] No text and no reaction from AI. Forcing fallback reaction for ${candidateId}.`);
                aiResult.reaction = 'üëç'; // Baseline presence
            }
            responseTextVal = null; // Clean up for internal logic
        }

        console.log(`[Consolidated Sync] Candidate ${candidateId}: `, candidateUpdates);
        const updatePromise = updateCandidate(candidateId, candidateUpdates);

        // --- MESSAGE REACTIONS (AI DRIVEN) ---
        let reactionPromise = Promise.resolve();
        const aiReaction = aiResult.reaction; // This now includes the fallback if needed

        if (msgId && config && aiReaction) {
            console.log(`[AI Reaction] üß† Brenda chose: ${aiReaction} for ${candidateId}`);
            reactionPromise = sendUltraMsgReaction(config.instanceId, config.token, msgId, aiReaction);
        }

        // --- MOVE KANBAN LOGIC ---
        const moveToken = (aiResult.thought_process || '').includes('{ move }');
        if (moveToken && candidateData.projectMetadata?.projectId) {
            const project = await getProjectById(candidateData.projectMetadata.projectId);
            const steps = project?.steps || [];
            const currentIndex = steps.findIndex(s => s.id === (candidateData.projectMetadata.stepId || 'step_new'));
            if (currentIndex !== -1 && steps[currentIndex + 1]) {
                await moveCandidateStep(project.id, candidateId, steps[currentIndex + 1].id);
            }
        }

        // Final Persistence
        let deliveryPromise = Promise.resolve();

        if (responseTextVal) {
            deliveryPromise = sendUltraMsgMessage(config.instanceId, config.token, candidateData.whatsapp, responseTextVal);
        } else {
            console.log(`[Presencia Constante] Text suppressed for ${candidateId}. Final Reaction: ${aiResult.reaction}`);
        }

        // --- STICKER CELEBRATION (AI DRIVEN + AUDIT SHIELD) ---
        const hasBeenCongratulated = candidateData.congratulated === true || candidateData.congratulated === 'true';
        let stickerPromise = Promise.resolve();
        const finalMerged = { ...candidateData, ...candidateUpdates };
        const finalAudit = auditProfile(finalMerged, customFields);
        const isNowComplete = finalAudit.paso1Status === 'COMPLETO';

        const shouldSendSticker = (aiResult.trigger_media === 'success_sticker' || (initialStatus === 'INCOMPLETO' && isNowComplete))
            && isNowComplete
            && !hasBeenCongratulated;

        if (shouldSendSticker) {
            const stickerUrl = await redis?.get('bot_celebration_sticker');
            if (stickerUrl) {
                console.log(`[CELEBRATION] üé® Sending validated sticker to ${candidateData.whatsapp}: ${stickerUrl}`);
                stickerPromise = sendUltraMsgMessage(config.instanceId, config.token, candidateData.whatsapp, stickerUrl, 'sticker');
                candidateUpdates.congratulated = true;
            }
        }

        await Promise.allSettled([
            deliveryPromise,
            stickerPromise,
            reactionPromise,
            saveMessage(candidateId, { from: 'bot', content: responseTextVal || '[REACCI√ìN/SILENCIO]', timestamp: new Date().toISOString() }),
            updatePromise
        ]);

        return responseTextVal || '[SILENCIO]';

    } catch (error) {
        console.error('‚ùå [AI Agent] Fatal Error:', error);
        const fallbackMsg = "¬°Ay, perdona! Me hablaron de otra oficina y me distraje un segundo. üòÖ ¬øMe repites lo √∫ltimo? üòä";
        await sendFallback(candidateData, fallbackMsg).catch(() => { });
        return fallbackMsg;
    }
};

async function sendFallback(cand, text) {
    const config = await getUltraMsgConfig();
    if (config && cand.whatsapp) {
        await sendUltraMsgMessage(config.instanceId, config.token, cand.whatsapp, text);
    }
}
// [Vercel Deployment Ping: f678976 Stable Version Restored]
